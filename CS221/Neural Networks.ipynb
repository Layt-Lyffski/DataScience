{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral Networks\n",
    "---\n",
    "Algorithms that try to mimic the brain.<br>\n",
    "## Representation\n",
    "---\n",
    "##### Notation\n",
    "$a_i^{(j)}$ = \"activation\" of unit $i$ in layer $j$<br>\n",
    "$\\Theta^{(j)}$ = matrix of weigths/parameters controlling fucniton mapping formm layer $j$ to layer $j+$<br>\n",
    "L = total no. of layers in network <br>\n",
    "$s_l$ = no. of units (not counting bias unit) in layer $l$<br>\n",
    "\n",
    "If network has $s_j$ units in layer $j$, $s_j+1$ units in layer $j+1$, then$\\Theta^{(j)}$ will be of demeinsion $s_j+1\\times(s_j +1)$<br>\n",
    "__Thus__ neutral network is __compute succesfully__<br><br>\n",
    "\n",
    "##### Visualization by Andrew Ng\n",
    "<img src=\"pic\\forward_propagation.png\"><br>\n",
    "Given one training example(x,y): where $a^{(1)}$ input layer; rest hidden; $a^{(4)}$ output layer (Mulitclass)\n",
    "<img Src=\"pic\\1ex_forward_propagation.png\"><br>\n",
    "\n",
    "##### Intuition\n",
    "<img src=\"pic\\xnor_nn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "---\n",
    "#### Binary classifaction\n",
    "$y$ = 0 or 1<br>\n",
    "1 output unit<br>\n",
    "\n",
    "#### Mulit-class classification (K classes)\n",
    "$y from R^K$<br>\n",
    "K output units<br>\n",
    "### Cost function\n",
    "$h_\\theta(x)\\in\\mathbb{R}^K (h_\\theta(x))_i = i^th$ output; where pink is __Regularization__ and is sum over __$\\Theta_ji^{(l)}$__ without Regulaizred the __Bais__ && green taking the $h$ and compare it to the $y$ which tell the right __\"classified\"__ result\n",
    "\n",
    "$$J(\\Theta)=-\\frac{1}{m} [ \\sum_\\limits{i=1}^m \\sum_\\limits{k=1}^K \\color{green}{y_k^{(i)}} log\\color{green}{(h_\\theta(x^{(i)}))_k} + (1-y_k^{(i)}) log(1-(h_\\theta(x^{(i)}))_k) ] + \\color{pink}{\\frac{\\lambda}{2m}\\sum_\\limits{l=1}^{L-1} \\sum_\\limits{i=1}^{s_1} \\sum_\\limits{j=1}^{s_l+1}(\\Theta_ji^{(j)})^2}$$\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
